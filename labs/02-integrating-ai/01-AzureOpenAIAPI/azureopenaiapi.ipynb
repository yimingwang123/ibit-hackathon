{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Working with the Azure OpenAI API directly\n",
    "\n",
    "In this lab, we will perform a simple call to the Azure OpenAI API. This will prove that everything is setup correctly and working for the rest of the labs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to retrieve values from the `.env` file which we will use to make calls to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://ai-admin6169ai032713463879.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the API\n",
    "\n",
    "Now let's call the Azure OpenAI API with a prompt. To do this, we'll need the `id` of the Azure OpenAI deployment that contains our completion model. This should already be setup in the `.env` file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct a URL to call so that you can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ai-admin6169ai032713463879.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview\n"
     ]
    }
   ],
   "source": [
    "API_URL = os.getenv(\"AZURE_OPENAI_COMPLETION_URL\")\n",
    "url = API_URL\n",
    "print(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the full URL that we are going to call. This URL will use the specified deployment to call the **chat completions** API.\n",
    "\n",
    "Next, we will call the Azure OpenAI API using the URL above. We pass the API key in the HTTP header. We also send a JSON formatted body as part of the request which contains the *prompt* that we want to use to get a response from the OpenAI model. In this case, our prompt is \"Once upon a time\", which should cause the model to complete the prompt by generating a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Once upon a time in a forest teeming with vibrant colors and endless mysteries, there lived a kind-hearted cat named Luna. Luna was no ordinary feline\\u2014her gray fur shimmered under the sunlight, and her emerald-green eyes sparkled as if holding secrets of the universe. She lived on the edge of the Enchanted Woods, a place whispered about by the villagers as magical and full of wonder.\\n\\nEvery animal in the forest admired Luna for her curiosity and her courage, for she would often help her fellow creatures with her quick wit and calm demeanor. However, despite her bravery, Luna had always been cautious about venturing too far into the inner depths of the Enchanted Woods. It was rumored that the deepest parts held untold treasures guarded by puzzles and riddles almost impossible to solve.\\n\\nOne autumn morning, as the leaves turned crimson and gold, Luna found a peculiar scroll carried by the wind. It nestled softly beside her favorite spot near the old oak tree. Curious, she unrolled it carefully. The scroll bore a riddle written in shimmering silver ink:\\n\\n*\\\"To the heart of magic, take this trail,  \\nFollow the song where whispers prevail.  \\nA treasure you'll find if you dare,  \\nBut answer true with wisdom rare.\\\"*\\n\\nIntrigued and unable to resist the lure of adventure, Luna decided that perhaps it was time to follow her instincts and face the enchantment herself. And so, with a deep breath and a determined spirit, Luna embarked on her journey to uncover the forest's hidden mysteries, setting her first paw print deeper into the Enchanted Woods than she\\u2019d ever gone before.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1739360701,\n",
      "  \"id\": \"chatcmpl-B05SnFOjyDiTO8cnz2cuJlfEnfKEa\",\n",
      "  \"model\": \"gpt-4o-2024-11-20\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"system_fingerprint\": \"fp_f3927aa00d\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 326,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 338\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "r = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": \"Once upon a time \"}]})\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Response Format\n",
    "\n",
    "The result of the API call will be JSON data similar to the example below. Note that the response has been edited for brevity and readability.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"chatcmpl-B05SnFOjyDiTO8cnz2cuJlfEnfKEa\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1739360701,\n",
    "  \"model\": \"gpt-4o-2024-11-20\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Once upon a time in a forest teeming with vibrant colors...\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 326,\n",
    "    \"prompt_tokens\": 12,\n",
    "    \"total_tokens\": 338\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here's some information about some of the more interesting pieces of data contained in that response.\n",
    "\n",
    "Key | Description\n",
    "--- | ---\n",
    "`model` | The model that was used to generate the response to the prompt\n",
    "`content` | This is the response that was generated by the OpenAI model. Note that the response example above was edited to remove most of the output to make it easier to read\n",
    "`finish_reason` | This is the reason that the model stopped generating the response. In this case, `stop` indicates the model determined it had fully completed the response without hitting any limits\n",
    "`completion_tokens` | The number of tokens that were used in generating the response\n",
    "`prompt_tokens` | The number of tokens that were consumed by the prompt\n",
    "`total_tokens` | The total number of tokens that were consumed by the request (`prompt_tokens` + `completion_tokens`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we used the Azure OpenAI API directly to send a prompt to an OpenAI model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we will look at using the OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [OpenAI Packages/Libraries](../02-OpenAIPackages/openai.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibit-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
